# 250114 숙제 2일차(도커&클라우드)

### Q. 윈도우에서 WSL을 설치한 후, 그 위에서 도커를 돌리면 WSL이 램을 차지하여 애플리케이션 실행이 끊기는 경우가 있는데, 이 문제는 어떻게 해결할 수 있나요?

A. 이 문제는 윈도우 환경에서 WSL과 도커를 사용하는 구조적인 한계에서 발생합니다. 램과 CPU 자원을 사용하는 컨테이너가 과부하 상태에 빠지면 애플리케이션 성능 저하나 중단이 발생할 수 있습니다. 그래서 대부분의 aws와 같이 클라우드 서버의 os는 linux를 사용하는 것 같습니다.  컨테이너도 일정량의 램과 cpu를 할당 받아서 애플리케이션을 돌리는 거다 보니까 작업 부하가 큰 (처리해야될 연산량이 많은) 경우에는 컨테이너가 죽거나 고장나는 경우가 있습니다. 이럴 경우

1. WSL의 리소스 제한 조정 : WSL은 기본적으로 사용할 수 있는 메모리와 CPU를 제한 없이 할당합니다. 이를 방지하려면, WSL 설정 파일(`.wslconfig`)을 생성하여 리소스 제한을 설정할 수 있습니다
    
    ```
    [wsl2]
    memory=4GB  # 최대 메모리 사용량
    processors=2  # 최대 CPU 사용량
    ```
    

1. 도커 컨테이너의 리소스 관리 : 도커 컨테이너를 실행할 때 리소스 제한을 설정하여 과도한 사용을 방지할 수 있습니다. 이것은 애플리케이션 운영 상 근본적인 해결법이라고 보기 어려울 것 같습니다 ..
    
    ```bash
    docker run --memory="2g" --cpus="1.5" your-container
    ```
    
2. 애플리케이션의 작업 부하 최적화 : 작업 부하가 큰 애플리케이션은 과도한 연산으로 인해 중단될 수 있습니다. 이 경우, 작업 부하를 분산하거나 애플리케이션의 성능을 최적화해야 합니다.
3. 자동 재시작 설정: 도커 컨테이너에 —restart 옵션을 추가하여 컨테이너가 비정상적으로 종료될 경우 자동으로 재시작되도록 설정한다. 
    
    ```bash
    docker run --restart=always your-container
    ```
    
4. 클라우드 서비스 이용 : 윈도우에서 리소스 한계가 자주 발생한다면, AWS와 같은 클라우드 서비스를 이용하여 리눅스 기반의 환경에서 컨테이너를 실행하는 것도 방안이 될 수 있습니다.
5. 볼륨 및 데이터 구조 재설정 : 특정 애플리케이션이 지속적으로 문제가 발생한다면, 컨테이너화 시 볼륨 매핑과 데이터 구조를 재설계하여 애플리케이션의 안정성을 높일 필요가 있습니다.

---

---

## 애플리케이션/서비스를 클라우드에 도커로 컨테이너화하여 배포하는 과정과 그 이유

: 우리 프로젝트에서 도커를 사용하는 이유에 대해 생각하는 과정 중에 우리의 서비스를 클라우드에 도커로 컨테이너화하여 배포하는 과정과 이러한 방법을 택한 이유를 공부했습니다. 

1. **도커로 우리의 서비스를 컨테이너화 하는 과정**
    1. 애플리케이션 개발 : 적절한 언어와 프레임워크, 라이브러리 등을 활용해 코드를 작성합니다.
    2. Dockerfile 작성
        
        ```docker
        # Base 이미지 선택 (Java 런타임 환경 포함)
        FROM openjdk:17
        
        # 작업 디렉토리 설정
        WORKDIR /app
        
        # 애플리케이션 JAR 파일 복사
        COPY target/my-springboot-app.jar /app/my-springboot-app.jar
        
        # 애플리케이션 실행
        CMD ["java", "-jar", "A301-app.jar"]
        ```
        
    3. 도커 이미지 빌드 : 작성된 Dockerfile을 기반으로 이미지를 생성합니다. 
        
        ```bash
        docker build -t my-application
        ```
        
    4. 컨테이너 실행 및 테스트 : 생성된 도커 이미지를 실행하여 로컬에서 애플리케이션이 제대로 작동하는지 테스트합니다. 
    5. 도커 이미지 배포 준비 : 이미지가 정상적으로 동작한다면 이를 컨테이너 레지스트리 (ex. Docker Hub, AWS ECR 등 ..)에 업로드합니다.
2. 클라우드에 배포
    1. 클라우드 플랫폼 선택 : AWS, GCP와 같은 클라우드 제공자를 선택합니다.
    2. 컨테이너 오케스트레이션 도구 설정 (단일 컨테이너를 배포할 땐 필수가 아님. 소규모 프로젝트와 정적인 트래픽 및 리소스를 요구할 때도 ..)
        
        ** 오케스트레이션은 클러스터를 효율적으로 관리하고 자동화하는 프로세스를 의미합니다. 여러 노드와 컨테이너를 관리하여 애플리케이션이 적절하게 실행되도록 보장합니다. 
        
        *** 기능 1) 컨테이너 배포 : 컨테이너를 어떤 노드에서 실행할지 결정
        
        *** 기능 2) 리소스 할당 : CPU, 메모리 등 시스템 자원을 최적화
        
        *** 기능 3) 확장 및 축 : 트래픽에 따라 컨테이너의 개수를 동적으로 조절
        
        *** 기능 4) 복구 및 자가 치유 : 문제가 생긴 컨테이너를 자동으로 재시작
        
        *** 기능 5) 로드 밸런싱 : 여러 노드와 컨테이너 간 트래픽 분배
        
        *** 기능 6) 모니터링 : 애플리케이션 상태를 확인하고 로그를 관리
        
        - 쿠버네티스 : 컨테이너의 배포, 스케일링, 관리를 담당하는 오케스트레이션 도구입니다.
        - AWS ECS, Google Kubernetes Engine, Azure Kubernetes Service 등 플랫폼 별 서비스 설정을 시작합니다.
    3. 클러스터 설정 : 클러스터를 생성하고 필요한 노드를 구성합니다. 예를 들어 AWS EKS를 사용하는 경우 다음과 같이 진행합니다.
        
        ** 클러스터 : 여러 대의 물리적 또는 가상 머신(노드)을 하나의 시스템처럼 동작하도록 구성한 환경. 클러스터는 리소스(컴퓨팅 파워, 메모리, 네트워크 등)를 공유하며, 하나의 목표(애플리케이션 실행, 데이터 처리 등)을 위해 협력합니다. 
        
        - 클러스터 생성
        - 워커 노드 설정
    4. 이미지 배포 : 컨테이너 이미지를 클러스터로 배포합니다. 쿠버네티스를 사용하는 경우, Deployment와 Service를 정의한 YAML 파일을 작성해 배포합니다. 
        
        ```yaml
        # 쿠버네티스 API 버전 정의 (이 부분은 천천히 다시 살펴봐야 할 것 같음)
        apiVersion: apps/v1 # Deployment 객체를 정의하기 위해 사용하는 API qjwjs
        kind: Deployment # 배포(Deployment) 객체를 정의
        metadata:
          name: A301 #Deployment의 이름 (클러스터 내 고유 식별자)
        spec:
          replicas: 3 # 동일한 파드를 3개 복제하여 실행 (수평적 확장)
          selector:
            matchLabels:
              app: A301 # 이 Deployment가 관리할 파드를 선택하는 기준 (라벨 매칭)
          template:
            metadata:
              labels:
                app: A301 # 생성할 파드에 부여될 라벨 (selector와 일치해야 함)
            spec:
              containers:
              - name: A301 # 컨테이너의 이름
                image: kihwn/A301:latest #사용할 도커 이미지
                ports:
                - containerPort: 8080 # 컨테이너 내부에서 열리는 포트번호
        ---
        #Service 객체 정의
        apiVersion: v1 #Service 객체를 정의하기 위한 API 버전
        kind: Service #클러스터 내 네트워크 서비스 정의
        metadata:
          name: A301Service #서비스의 이름 (클러스터 내 고유 식별자)
        spec:
          selector:
            app: A301 # 이 서비스가 트래픽을 전달할 대상 파드의 라벨
          ports:
          - protocol: TCP # 사용할 네트워크 프로토콜
            port: 80 # 서비스가 외부에서 노출하는 포트
            targetPort: 8080 # 파드의 컨테이너가 사용하는 포트
          type: LoadBalancer # 클라우드 제공자를 통해 외부에 로드 밸런서를 생성
        ```
        
    5. 배포 및 스케일링 : 클러스터에 배포한 애플리케이션은 트래픽에 따라 자동으로 스케일링이 가능합니다.
        
        ```bash
        kubectl apply -f deployment.yaml
        ```
        
    6. 모니터링 및 유지 관리 : 클라우드 플랫폼이 제공하는 모니터링 도구 (AWS CloudWatch, GCP Stackdriver 등)를 활용해 서비스 상태를 지속적으로 확인하고, 필요시 업데이트합니다.

---

---

## 도커로 컨테이너화하여 배포하는 이유

1. 환경의 일관성 : 도커는 애플리케이션이 실행되는 환경(운영 체제, 의존성, 설정 등)을 컨테이너로 고립시킵니다. 개발, 테스트, 운영 환경이 동일하게 유지되므로, “내 로컬에서는 잘 되는데 서버에서는 안돼요”라는 문제가 발생하지 않습니다.
2. 빠른 배포와 복구 : 컨테이너는 가볍고 실행 속도가 빠릅니다. 따라서 배포 시간이 단축되고, 장애 발생 시 빠르게 복구할 수 있습니다.
3. 스케일링 용이성 : 컨테이너는 수평적 확장이 쉬워 트래픽 증가 시 컨테이너 개수를 늘려 부하를 분산할 수 있습니다.
4. 리소스 효율성 : 컨테이너는 기존의 VM보다 가볍습니다. 필요 리소스만 사용하므로, 하드웨어 자원을 효율적으로 활용할 수 있습니다.
5. CI/CD와의 호환성 : 도커는 CI/CD 파이프라인에서 소스 코드 빌드, 테스트, 배포까지 통합적으로 관리하기에 적합합니다.
6. 플랫폼 종속성을 줄이고, 배포 환경을 일관되게 유지 : 도커는 클라우드 제공자에 구애받지 않고 사용할 수 있습니다. 이를 통해 멀티 클라우드 환경에서도 동일한 설정으로 애플리케이션을 배포할 수 있습니다. 

위와 같은 이유와 더불어 여러 팀원이 함께하는 프로젝트에서 개발 환경을 통일하는 등의 장점으로 인해 저희 팀에서는 도커를 사용하기로 결정했습니다.